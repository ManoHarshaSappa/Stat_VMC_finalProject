[
  {
    "objectID": "Project Details.html",
    "href": "Project Details.html",
    "title": "Project Details",
    "section": "",
    "text": "The Dataset, sourced from the Maryland State Police’s Automated Crash Reporting System, encompasses traffic collisions in Montgomery County, MD, from 2020 to 2023, comprising 172,106 rows and 43 columns. It provides details on collision dates, locations, vehicle types, driver conditions, and fault attributions, facilitating analysis of collision trends and the development of predictive models for road safety measures. The dataset can be accessed through the following\nURL: https://catalog.data.gov/dataset/crash-reporting-drivers-data"
  },
  {
    "objectID": "Project Details.html#dataset",
    "href": "Project Details.html#dataset",
    "title": "Project Details",
    "section": "",
    "text": "The Dataset, sourced from the Maryland State Police’s Automated Crash Reporting System, encompasses traffic collisions in Montgomery County, MD, from 2020 to 2023, comprising 172,106 rows and 43 columns. It provides details on collision dates, locations, vehicle types, driver conditions, and fault attributions, facilitating analysis of collision trends and the development of predictive models for road safety measures. The dataset can be accessed through the following\nURL: https://catalog.data.gov/dataset/crash-reporting-drivers-data"
  },
  {
    "objectID": "Project Details.html#traffic-incident-dataset-column-descriptions",
    "href": "Project Details.html#traffic-incident-dataset-column-descriptions",
    "title": "Project Details",
    "section": "Traffic Incident Dataset Column Descriptions:",
    "text": "Traffic Incident Dataset Column Descriptions:\n\n\n\n\n\n\n\n\n\n\nNo\nColumn Name\nData Type\nExplanation\nExample Values\n\n\n\n\n1\nReport Number\nObject\nUnique identifier for each incident report.\n“RPT2024-001”, “RPT2024-002”,..\n\n\n2\nLocal Case Number\nObject\nIdentifier within the local jurisdiction.\n“LCN001”, “LCN002”,..\n\n\n3\nAgency Name\nObject\nOrganization handling the incident report.\n“Police Department”, “DOT”,..\n\n\n4\nACRS Report Type\nObject\nType of report per the Administrative Code Reporting System.\n“Crash”, “Incident”,..\n\n\n5\nCrash Date/Time\nObject\nDate and time when the crash occurred.\n“2024-04-30 14:30:00”,..\n\n\n6\nRoute Type\nObject\nType of route where the crash happened.\n“Highway”, “Local Road”,..\n\n\n7\nRoad Name\nObject\nName of the road where the crash occurred.\n“Main Street”, “Broadway”,..\n\n\n8\nCross-Street Type\nObject\nType of intersecting street.\n“Street”, “Avenue”,..\n\n\n9\nCross-Street Name\nObject\nName of the intersecting street.\n“Elm Street”, “Maple Avenue”,..\n\n\n10\nOff-Road Description\nObject\nDescription if crash occurred off-road.\n“Parking Lot”, “Field”,..\n\n\n11\nMunicipality\nObject\nCity or town where the crash occurred.\n“City A”, “Town B”,..\n\n\n12\nRelated Non-Motorist\nObject\nNon-motorist involved in the incident.\n“Pedestrian”, “Cyclist”,..\n\n\n13\nCollision Type\nObject\nType of collision.\n“Rear-end”, “Head-on”,..\n\n\n14\nWeather\nObject\nWeather conditions at the time of the crash.\n“Clear”, “Rain”,..\n\n\n15\nSurface Condition\nObject\nRoad surface condition at the time of the crash.\n“Dry”, “Wet”,..\n\n\n16\nLight\nObject\nLighting conditions at the time of the crash.\n“Daylight”, “Dark”,..\n\n\n17\nTraffic Control\nObject\nType of traffic control at the scene.\n“Traffic Signal”, “Stop Sign”,..\n\n\n18\nDriver Substance Abuse\nObject\nWhether driver was under substance influence.\n“Yes”, “No”,..\n\n\n19\nNon-Motorist Substance Abuse\nObject\nWhether non-motorist was under substance influence.\n“Yes”, “No”,..\n\n\n20\nPerson ID\nObject\nUnique identifier for individuals involved.\n“PID001”, “PID002”,..\n\n\n21\nDriver At Fault\nObject\nWhether driver was at fault.\n“Yes”, “No”,..\n\n\n22\nInjury Severity\nObject\nSeverity of injuries sustained.\n“Fatal”, “Minor Injury”,..\n\n\n23\nCircumstance\nObject\nSpecific circumstances surrounding the incident.\n“Speeding”, “Distracted Driving”,..\n\n\n24\nDriver Distracted By\nObject\nWhat the driver was distracted by.\n“Cell Phone”, “Passenger”,..\n\n\n25\nDrivers License State\nObject\nState where driver’s license was issued.\n“CA”, “NY”,..\n\n\n26\nVehicle ID\nObject\nUnique identifier for vehicles involved.\n“VID001”, “VID002”,..\n\n\n27\nVehicle Damage Extent\nObject\nExtent of damage to the vehicle.\n“Minor”, “Severe”,..\n\n\n28\nVehicle First Impact Location\nObject\nLocation on vehicle of first impact.\n“Front”, “Rear”,..\n\n\n29\nVehicle Second Impact Location\nObject\nLocation on vehicle of second impact.\n“Side”, “Front”,..\n\n\n30\nVehicle Body Type\nObject\nType of vehicle body.\n“Sedan”, “SUV”,..\n\n\n31\nVehicle Movement\nObject\nMovement of the vehicle at the time of the crash.\n“Stopped”, “Moving”,..\n\n\n32\nVehicle Continuing Dir\nObject\nDirection vehicle continued after crash.\n“North”, “East”,..\n\n\n33\nVehicle Going Dir\nObject\nDirection vehicle was going at time of crash.\n“South”, “West”,..\n\n\n34\nSpeed Limit\nInt64\nSpeed limit of road where crash occurred.\n30, 55,..\n\n\n35\nDriverless Vehicle\nObject\nWhether vehicle was driverless (autonomous).\n“Yes”, “No”,..\n\n\n36\nParked Vehicle\nObject\nWhether vehicle was parked at time of crash.\n“Yes”, “No”,..\n\n\n37\nVehicle Year\nInt64\nYear of manufacture of the vehicle.\n2019, 2022\n\n\n38\nVehicle Make\nObject\nMake or brand of the vehicle.\n“Toyota”, “Ford”,..\n\n\n39\nVehicle Model\nObject\nModel of the vehicle.\n“Camry”, “F-150”,..\n\n\n40\nEquipment Problems\nObject\nAny equipment problems contributing to crash.\n“Brake Failure”, “Tire Blowout”,..\n\n\n41\nLatitude\nFloat64\nLatitude coordinate of crash location.\n40.7128, 34.0522,..\n\n\n42\nLongitude\nFloat64\nLongitude coordinate of crash location.\n-74.0060, -118.2437,..\n\n\n43\nLocation\nObject\nDescription or address of crash location.\n“123 Main St, City A”,..\n\n\n\n\nThis table provides a clear overview of each column in the dataset, its data type, an explanation of what the column represents, and example values for better understanding."
  },
  {
    "objectID": "Research Design.html",
    "href": "Research Design.html",
    "title": "Research Design",
    "section": "",
    "text": "1. Visualization1: What are the trends in the frequency of car crashes over years?\n\nMethodology - To analyze the trend of crash frequency over the years, we will use ggplot2 in R. This allows us to create visual representations of data. We’ll transform the Crash_Date column into a date format and group the data by year. By visualizing this data, we can identify any noticeable patterns or trends in crash frequency over time.\n\n\n\n2. Visualization2: How does the distribution of car accidents vary geographically?\n\nMethodology - To understand the geographical distribution of car accidents, we will utilize the Leaflet package in R. This package enables us to create interactive maps displaying crash locations and associated fatalities using latitude and longitude data. By visualizing this data on a map, we can identify any geographic patterns or hotspots where accidents are more prevalent.\n\n\n\n3. Visualization3: Top 10 cars which involve in car cashes?\n\nMethodology - To identify the top 10 car manufacturers involved in car accidents, we will generate a bar plot using ggplot2 in R. This plot will showcase the most common vehicle makes involved in accidents. We’ll use dplyr for data summarization and arrangement to identify the top 10 manufacturers based on accident frequency.\n\n\n\n4. Hypothesis #1: Is there any relation between weather conditions, daylight, and injury severity?\nQuestion: - Is there any relation between weather conditions, daylight, and injury severity?\n\nMethodology - To test this hypothesis, we will conduct a Pearson’s Chi-squared test on a contingency table. This test will analyze the association between weather conditions, daylight, and injury severity. By examining the relationship between these variables statistically, we can determine if there’s a significant correlation between them.\n\n\n\n5. Hypothesis #2: Are certain types of vehicles more likely to be involved in collisions at night compared to during the day?\n\nMethodology - To investigate this hypothesis, we will perform a Pearson’s Chi-squared test comparing collision counts involving different types of vehicles during the day and at night. By statistically analyzing collision data, we can determine if certain vehicle types are more prone to accidents during specific times of the day.\n\n\n\n6. Hypothesis #3: Do drivers distracted by electronic devices have a higher rate of collisions compared to drivers distracted by other factors?\n\nMethodology - To explore this hypothesis, we will conduct a Chi-squared test comparing collision counts between drivers distracted by electronic devices and those distracted by other factors. By examining collision data and analyzing distraction-related factors, we can determine if electronic device distraction significantly impacts collision rates.\n\n\n\n7. Hypothesis #4: Can we determine the effectiveness of different traffic control measures in reducing collision rates? Which types of traffic controls are most effective in preventing collisions?\n\nMethodology - To address this hypothesis, we will conduct a Pearson’s Chi-squared test between traffic control measures and injury severity. By statistically analyzing data on traffic control measures and their impact on collision rates, we can assess the effectiveness of various measures and identify the most impactful ones for preventing collisions.\n\n\n\n8. Prediction #1: Can we predict the severity of injuries based on various factors such as weather conditions, road surface conditions, and collision type?\n\nMethodology - To make predictions about injury severity, we will utilize a random forest classification model trained on relevant dataset. This model will analyze various factors such as weather conditions, road surface conditions, and collision type to predict injury severity. By assessing the model’s accuracy and performance, we can determine its effectiveness in predicting injury severity.\n\n\n\n9. Prediction #2: Can we predict the extent of vehicle damage in collisions based on collision type, vehicle movement, and speed limit?\n\nMethodology - To make predictions about vehicle damage extent, we will evaluate model performance using confusion matrix and key predictors. By analyzing collision data and training a predictive model, we can assess its accuracy in predicting the extent of vehicle damage based on collision type, vehicle movement, and speed limit."
  },
  {
    "objectID": "fp.html",
    "href": "fp.html",
    "title": "Final Project",
    "section": "",
    "text": "Group Number: 14"
  },
  {
    "objectID": "fp.html#what-is-project-based-on",
    "href": "fp.html#what-is-project-based-on",
    "title": "Final Project",
    "section": "What is Project based on?",
    "text": "What is Project based on?\n\nOur project revolves around a thorough examination of a dataset documenting motor vehicle collisions on county and local roadways within Montgomery County, Maryland. This dataset serves as the cornerstone for our investigation into the myriad factors that influence traffic accidents and their consequences. Through meticulous analysis and advanced statistical techniques, we aim to uncover insightful patterns and correlations that can inform proactive measures for enhancing road safety and mitigating accident risks.\nIn our endeavor, we transcend conventional data exploration by incorporating hypothesis testing and predictive modeling methodologies. By formulating and testing hypotheses pertaining to weather conditions, daylight, injury severity, vehicle types, distractions, and traffic control measures, we strive to unveil underlying relationships and trends within the data. Additionally, our predictive modeling efforts seek to anticipate injury severity and vehicle damage extent based on a diverse set of variables including collision type, vehicle movement, and speed limit. Through this comprehensive approach, our project aspires to deliver actionable insights that can empower stakeholders in making informed decisions aimed at fostering safer road environments and reducing the occurrence of motor vehicle collisions."
  },
  {
    "objectID": "fp.html#whats-our-goal",
    "href": "fp.html#whats-our-goal",
    "title": "Final Project",
    "section": "What’s our Goal?",
    "text": "What’s our Goal?\n\nOur goal is to deeply understand why and how motor vehicle collisions happen in Montgomery County, Maryland. By analyzing a vast amount of data on these accidents, we aim to uncover patterns, trends, and correlations that shed light on the factors contributing to crashes. Through this exploration, we seek to identify key variables such as weather conditions, road surfaces, vehicle types, and driver behaviors that play significant roles in accident occurrence and severity.\nUltimately, our aim is to use this knowledge to inform strategies and interventions that can enhance road safety and reduce the frequency and severity of motor vehicle collisions. By providing insights into the root causes and contributing factors of accidents, we aspire to empower policymakers, law enforcement agencies, and community stakeholders with the information they need to implement effective measures for preventing accidents and safeguarding lives on the roads of Montgomery County."
  },
  {
    "objectID": "fp.html#research-questions",
    "href": "fp.html#research-questions",
    "title": "Final Project",
    "section": "Research Questions :",
    "text": "Research Questions :"
  },
  {
    "objectID": "fp.html#visualization1-what-are-the-trends-in-the-frequency-of-car-crashes-over-years",
    "href": "fp.html#visualization1-what-are-the-trends-in-the-frequency-of-car-crashes-over-years",
    "title": "Final Project",
    "section": "Visualization1 : What are the trends in the frequency of car crashes over years?",
    "text": "Visualization1 : What are the trends in the frequency of car crashes over years?\n\nGraph:\n\n\n\nCode\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read data and remove missing values\ndata &lt;- read.csv('/Users/manoharshasappa/Desktop/Stat_Final_project de/CrashReportingDriversData.csv')\ndata &lt;- na.omit(data)\n\n# Convert Crash_Date to a Date format\ndata$Crash_Date &lt;- as.Date(data$Crash.Date.Time, format = \"%m/%d/%Y %I:%M:%S %p\")\n\n# Extract year from Crash_Date\ndata$Year &lt;- format(data$Crash_Date, \"%Y\")\n\n# Group the data by year and count the number of crashes\nyearly_crash_count &lt;- data %&gt;%\n  group_by(Year) %&gt;%\n  summarise(Num_Crashes = n())\n\n# Provided data\nyearly_crash_data &lt;- data.frame(\n  Year = c(\"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"),\n  Num_Crashes = c(20268, 21783, 21537, 21035, 20943, 13798, 16210, 17577, 18913, 7))\n\n# Plot using ggplot2\nplot1 = ggplot(yearly_crash_data, aes(x = Year, y = Num_Crashes)) +\n  geom_bar(stat = \"identity\", fill = \"#1F78B4\") +  # Adjusted color\n  labs(title = \"Crash Frequency per Year\",\n       x = \"Year\",\n       y = \"Number of Crashes\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# plot1\n\n\nColumns Used:\n\nNum_Crashes: This is the variable we are trying to understand or predict. It represents the number of crashes that occurred each year and is the primary focus of our analysis.\nYear: This is the predictor variable used to group the data. It represents the temporal aspect of the analysis, allowing us to observe how crash frequency changes over different years.\nCrash_Date: Though not explicitly used in this particular plot, Crash_Date could be considered a predictor variable in a more detailed analysis. It provides the specific date and time of each crash incident, which could be used to explore temporal patterns on a finer scale, such as monthly or daily trends. However, in this plot, it’s indirectly utilized to derive the Year variable.\n\n\n\nExplanation of the Code: This visualizes the frequency of crashes per year using ggplot2 in R. Initially, it converts the “Crash_Date” column into a date format and extracts the year from it. Then, it groups the data by year and calculates the number of crashes that occurred each year."
  },
  {
    "objectID": "fp.html#hypo4-can-we-determine-the-effectiveness-of-different-traffic-control-measures-traffic.control-in-reducing-collision-rates-which-types-of-traffic-controls-are-most-effective-in-preventing-collisions",
    "href": "fp.html#hypo4-can-we-determine-the-effectiveness-of-different-traffic-control-measures-traffic.control-in-reducing-collision-rates-which-types-of-traffic-controls-are-most-effective-in-preventing-collisions",
    "title": "Final Project",
    "section": "hypo#4: Can we determine the effectiveness of different traffic control measures (Traffic.Control) in reducing collision rates? Which types of traffic controls are most effective in preventing collisions?",
    "text": "hypo#4: Can we determine the effectiveness of different traffic control measures (Traffic.Control) in reducing collision rates? Which types of traffic controls are most effective in preventing collisions?\n\n\nInterpretation of Results: To analyze this, a Pearson’s Chi-squared test was conducted between the types of traffic control measures and the severity of injuries resulting from collisions. The output shows a significant relationship between the two variables, with a very low p-value (p &lt; 2.2e-16). This suggests that the effectiveness of traffic control measures in preventing collisions varies significantly across different types. However, further analysis would be needed to determine which specific types of traffic controls are most effective in reducing collision rates and severity of injuries.\n\nColumn used:\n\nCollision_Count: This variable represents the count of collisions for each type of traffic control. It is the response variable as it reflects the outcome of interest, i.e., the number of collisions categorized by the type of traffic control.\nTraffic.Control: This variable represents different types of traffic controls (e.g., stop sign, traffic signal). It serves as the predictor variable as it is used to categorize and group the collisions based on the type of traffic control present at the collision location.\n\n\nGraph :\n\n\n\nCode\n\n\n# Subset the dataset to include only the required columns\ntraffic_data &lt;- data[, c(\"Traffic.Control\", \"Injury.Severity\")]\n# Remove rows with any missing values\ntraffic_data &lt;- na.omit(traffic_data)\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\ntraffic_data[traffic_data == \"N/A\"] &lt;- NA\n\n# Remove rows with any missing values\ntraffic_data &lt;- na.omit(traffic_data)\n\n# Check if there are any missing values left\nprint(sum(is.na(traffic_data)))\n\n[1] 0\n\ncollision_counts &lt;- traffic_data %&gt;%\n  group_by(Traffic.Control) %&gt;%\n  summarise(Collision_Count = n())\n\n# Calculate collision rates for each traffic control type\ntotal_collisions &lt;- nrow(traffic_data)\ncollision_rates &lt;- collision_counts %&gt;%\n  mutate(Collision_Rate = Collision_Count / total_collisions)\n\n# Statistical Analysis\n# Perform chi-square test to compare collision rates between different traffic controls\nchi_square_test &lt;- chisq.test(traffic_data$Traffic.Control, traffic_data$Injury.Severity)\n\nWarning in chisq.test(traffic_data$Traffic.Control,\ntraffic_data$Injury.Severity): Chi-squared approximation may be incorrect\n\n# print(chi_square_test)\n# Visualization\n# par(mfrow=c(1, 2))  # Set up a 1x2 plotting grid\n\n# Create a bar plot using ggplot2\nplot3 = ggplot(collision_counts, aes(x = reorder(Traffic.Control, -Collision_Count), y = Collision_Count)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  labs(title = \"Collision Counts by Traffic Control Type\",\n       x = \"Traffic Control Type\",\n       y = \"Collision Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n# plot3\n\n\n\n\nPre1# Can we predict the severity of injuries based on various factors such as weather conditions, road surface conditions, and collision type?\n\nPredictor Variables: These are the factors or features used in a statistical model to predict or explain the outcome variable. In this context, “Weather,” “Surface.Condition,” and “Collision.Type” are predictors as they are hypothesized to influence the severity of crashes.\nResponse Variable: This is the outcome variable that the model aims to predict or explain. In this case, “Injury.Severity” represents the severity of injuries resulting from crashes. The model aims to understand how the predictor variables relate to the severity of injuries.\n\n\n\nData Pre Processing :\n\n\nIn this step, we are replacing character variables containing the text “N/A” with actual Null Values\n\n\n\nWe’re replacing missing values with null values and then eliminating those null values from the dataset.\n\n\n\n\nAccuracy :\n\n###kasdfdsf\n\n\n\nVariable importance plot:\n\n\n\n\nModel Evaluation & Improving:\n\n\n\nGraph :\n\n\n\ninterpretation\n\nUsing logistic regression to make our model better means it’s getting better at guessing correctly and telling the difference between things. It’s like it’s learning to understand the data more accurately. So, when we see accuracy and AUC (another way to measure how good it is) going up, it’s a sign that our model is getting smarter and more reliable at its job.\n\n\n\nCode\n\n\n# Load required library\n# library(randomForest)\n# library(caret)\n\n# Assuming your dataset is named 'data'\n\n# Select relevant columns for modeling\n# selected_cols &lt;- c(\"Weather\", \"Surface.Condition\", \"Collision.Type\", \"Injury.Severity\")\n\n# Subset the data\n# subset_data &lt;- data[selected_cols]\n\n# subset_data\n# Remove rows with any missing values\n# subset_data_clean &lt;- subset_data[complete.cases(subset_data), ]\n\n# subset_data_clean\n\n# Convert 'N/A' strings to NA\n# subset_data_clean[subset_data_clean == \"N/A\"] &lt;- NA\n\n# Remove rows with any missing values\n# subset_data_clean &lt;- na.omit(subset_data_clean)\n\n\n# Check if there are any missing values left\n# print(sum(is.na(subset_data_clean)))\n\n# subset_data_clean\n\n# Replace blank values with NA\n# subset_data_clean[subset_data_clean == \"\"] &lt;- NA\n\n# Remove rows with any missing values\n# subset_data_clean &lt;- na.omit(subset_data_clean)\n\n# Check if there are any missing values left\n# print(sum(is.na(subset_data_clean)))\n\n# subset_data_clean\n\n# Convert all columns to factors\n# subset_data_clean &lt;- as.data.frame(lapply(subset_data_clean, as.factor))\n\n# Verify the conversion\n# str(subset_data_clean)\n\n# Load required library\n# library(randomForest)\n# library(caret)\n\n# str(subset_data_clean)\n# Set seed for reproducibility\n# set.seed(123)\n\n# Split the data into training and testing sets\n# train_indices &lt;- createDataPartition(subset_data_clean$Injury.Severity, p = 0.8, list = FALSE)\n# train_data &lt;- subset_data_clean[train_indices, ]\n# test_data &lt;- subset_data_clean[-train_indices, ]\n# train_data\n# Fit random forest model\n# model &lt;- randomForest(Injury.Severity ~ ., data = train_data, ntree = 500)\n\n# Print model summary\n# print(model)\n\n# Make predictions on the test set\n# predictions &lt;- predict(model, newdata = test_data)\n\n# Create confusion matrix\n# conf_matrix &lt;- table(predictions, test_data$Injury.Severity)\n\n# Calculate accuracy\n# accuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\n\n# Evaluate the model using confusion matrix\n# conf_matrix &lt;- table(test_data$Injury.Severity, predictions)\n\n# Calculate accuracy\n# accuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\n\n# Print accuracy\n# print(paste(\"Accuracy:\", accuracy))\n\n# importance(model)\n\n# varImpPlot(model)\n\n# Predict on the test set\n# predictions &lt;- predict(model, newdata = test_data)\n\n# Confusion matrix\n# conf_mat &lt;- table(Actual = test_data$Injury.Severity, Predicted = predictions)\n# print(\"Confusion Matrix:\")\n# print(conf_mat)\n\n# Accuracy\n# accuracy &lt;- sum(diag(conf_mat)) / sum(conf_mat)\n# print(paste(\"Accuracy:\", accuracy))\n\n# Precision\n# precision &lt;- diag(conf_mat) / colSums(conf_mat)\n# print(paste(\"Precision:\", precision))\n\n# Recall (Sensitivity)\n# recall &lt;- diag(conf_mat) / rowSums(conf_mat)\n# print(paste(\"Recall:\", recall))\n\n# F1-score\n# f1_score &lt;- 2 * (precision * recall) / (precision + recall)\n# print(paste(\"F1-score:\", f1_score))\n\n# library(dplyr)\n\n# Assuming your dataset is named 'crash_data'\n\n# Select relevant columns for modeling\n# selected_cols &lt;- c(\"Weather\", \"Surface.Condition\", \"Collision.Type\", \"Injury.Severity\")\n\n# Subset the data\n# crash_data1 &lt;- data[selected_cols]\n\n\n\n# Remove rows with any missing values\n# crash_data1 &lt;- crash_data1[complete.cases(crash_data1), ]\n\n# crash_data1\n\n# Convert 'N/A' strings to NA\n# crash_data1[crash_data1 == \"N/A\"] &lt;- NA\n\n# Remove rows with any missing values\n# crash_data1 &lt;- na.omit(crash_data1)\n\n# Check if there are any missing values left\n# print(sum(is.na(crash_data1)))\n\n# crash_data1\n\n# Convert 'N/A' strings to NA\n# crash_data1[crash_data1 == \"\"] &lt;- NA\n\n# Remove rows with any missing values\n# crash_data1 &lt;- na.omit(crash_data1)\n\n# Check if there are any missing values left\n# print(sum(is.na(crash_data1)))\n\n# crash_data1\n\n# crash_data1 &lt;- crash_data1[, -which(names(crash_data1) == \"Injury.Severity\")]\n\n# crash_data1\n\n# logistic_model &lt;- glm(Severe_Injury ~ ., data = crash_data1, family = binomial)\n\n# summary(logistic_model)\n\n# Extract coefficients and standard errors\n# coefficients &lt;- summary(logistic_model)$coefficients[, \"Estimate\"]\n# standard_errors &lt;- summary(logistic_model)$coefficients[, \"Std. Error\"]\n\n# Predict probabilities using the logistic regression model\n# predicted_probs &lt;- predict(logistic_model, type = \"response\")\n\n# Convert probabilities to predicted classes\n# predicted_classes &lt;- ifelse(predicted_probs &gt; 0.5, 1, 0)\n\n# Actual classes\n# actual_classes &lt;- crash_data1$Severe_Injury\n\n# Accuracy\n# accuracy &lt;- mean(predicted_classes == actual_classes)\n# cat(\"Accuracy:\", accuracy, \"\\n\")\n\n# AUC-ROC\n# library(pROC)\n# roc_obj &lt;- roc(actual_classes, predicted_probs)\n# auc_roc &lt;- auc(roc_obj)\n# cat(\"AUC-ROC:\", auc_roc, \"\\n\")\n\n# Install and load the pROC package if you haven't already\n# library(pROC)\n\n# Assuming 'predicted_probs' contains the predicted probabilities and 'actual_classes' contains the actual classes (0 or 1)\n# roc_obj &lt;- roc(actual_classes, predicted_probs)\n\n# Plot ROC curve\n# plot(roc_obj, main = \"ROC Curve\", col = \"blue\")\n\n# Add text with AUC value\n# text(0.8, 0.2, paste(\"AUC =\", round(auc(roc_obj), 4)), col = \"blue\")#\n\n\n\n\nper#3: Find the locations of crashes using the K-means algorithm?\n\nFirst, we import some tools we need, like ggplot2 for making graphs and dplyr for managing data. Next, We pick out the latitude and longitude data from our dataset. This helps us group locations based on where they are.\nWe adjust the data so it’s all on the same scale. This helps us compare things more easily. It’s like making sure all the ingredients for a recipe are measured in the same units.\nWe try out different numbers of clusters to see which one works best. Think of it like trying to find the best number of groups for organizing your things. We use a method called the “elbow method” to help us decide.\n\n\n\nGraph: Elbow Method - K means\n\n\nThe elbow method suggests that the optimal number of clusters is 2, it means that adding more clusters doesn’t significantly improve the clustering quality, and two clusters are sufficient to capture the main patterns in the data effectively.\n\n\n\nGraph :\n\n\nOnce we figure out that two clusters are best for our data, we use a method called K-Means to group similar points together. It’s like sorting marbles into different colored bags based on how close they are to each other.\nThen, we tag each point with the cluster it belongs to. This lets us study and show which accidents are in which group.\nLastly, we make a picture showing all the accident spots. Each spot is colored according to its cluster, so we can see how they’re grouped together on a map. It helps us see patterns in where accidents happen.\nThe two clusters represent two distinct geographical regions or patterns of accidents within the dataset. Red cluster might represent areas with high accident density, while the other cluster might represent areas with lower accident frequency.\n\n\n\nCode\n\n\n# Load required libraries\n#library(ggplot2)\n#library(dplyr)\n\n# Assuming your dataset is called 'location_data' and contains columns 'Latitude' and 'Longitude'\n\n# Select latitude and longitude columns\n#location_data &lt;- data %&gt;% select(Latitude, Longitude)\n\n# Normalize data\n#normalized_data &lt;- scale(location_data)\n\n# Initialize vector to store within-cluster sum of squares (WCSS)\n#wcss &lt;- vector()\n\n# Iterate over different values of k\n#for (i in 1:10) {\n  # Apply K-Means algorithm\n # kmeans_model &lt;- kmeans(normalized_data, centers = i)\n  \n  #Store within-cluster sum of squares (WCSS)\n#  wcss[i] &lt;- kmeans_model$tot.withinss}\n\n# Plot the elbow curve\n#plot4 = elbow_plot &lt;- ggplot(data = data.frame(k = 1:10, WCSS = wcss), aes(x = k, y = WCSS)) +\n  #geom_line(color = \"blue\") +\n  #geom_point(color = \"red\") +\n  #labs(title = \"Elbow Method for Optimal K\",\n   #    x = \"Number of Clusters (k)\",\n  #     y = \"Within-Cluster Sum of Squares (WCSS)\") +\n  #scale_x_continuous(breaks = 1:10)\n\n# plot4\n\n\n#library(stats)\n#library(ggplot2)\n\n# Numerical columns for clustering\n#numerical_cols &lt;- c(\"Latitude\", \"Longitude\")\n\n# Subset the data with only numerical columns\n#numerical_data &lt;- data[, numerical_cols]\n\n# Standardizing numerical data\n#scaled_data &lt;- scale(numerical_data)\n\n# Determine the optimal number of clusters based on the elbow method\n#num_clusters &lt;- 2\n\n# Perform k-means clustering with the chosen number of clusters\n#kmeans_model &lt;- kmeans(scaled_data, centers = num_clusters)\n\n# Add cluster labels to the original dataset\n#data$Cluster &lt;- as.factor(kmeans_model$cluster)\n\n# Visualize the clusters\n#plot5 = ggplot(data = data, aes(x = Longitude, y = Latitude, color = Cluster)) +\n  #geom_point() +\n  #labs(title = \"Clustering of Accidents based on Location\") +\n  #theme_minimal()\n\n#plot5"
  },
  {
    "objectID": "fp.html#hypo1.-is-there-any-relation-between-weather-condition-day-light-on-injury-severity",
    "href": "fp.html#hypo1.-is-there-any-relation-between-weather-condition-day-light-on-injury-severity",
    "title": "Final Project",
    "section": "hypo#1. is there any relation between weather condition, day light on injury severity",
    "text": "hypo#1. is there any relation between weather condition, day light on injury severity\nThis test performs provided performs a chi-square test to determine whether there is a statistically significant association between weather condition, light condition, on injury severity, Here’s an explanation of why this test was conducted and what was observed:\n\nWeather and Light: This part of the analysis explores whether there’s a relationship between weather conditions (e.g., clear, rainy, snowy) and light conditions (e.g., daylight, dark with street lights, dark without street lights). For instance, the test can indicate whether certain weather conditions are more likely to occur in conjunction with specific light conditions. A significant result suggests that weather and light conditions are not independent of each other.\n\nChi-Square Test: The chi-square test is a statistical test used to determine whether there is a significant association between two categorical variables. In this case, the variables of interest are weather condition, light condition.\nObservation: By analyzing the contingency table generated from the data, which shows the frequency distribution of the combinations of weather condition, light condition, we can observe the following:\n\nThe contingency table provides counts of the number of accidents for each combination of weather condition, light condition.\nThe chi-square test is then applied to assess whether these variables are independent of each other or if there is a relationship between them.\n\n\n\n# Contingency table of Weather, Light, and Injury Severity\ncontingency_table &lt;- table(data$Weather, data$Light, data$Injury.Severity)\n\n# Remove any empty dimensions\ncontingency_table &lt;- margin.table(contingency_table, c(1, 2))\n\n\n# Chi-square test of independence\nchi_square_test &lt;- chisq.test(contingency_table)\n\nWarning in chisq.test(contingency_table): Chi-squared approximation may be\nincorrect\n\n# Print the test results\nprint(chi_square_test)\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table\nX-squared = 31341, df = 96, p-value &lt; 2.2e-16\n\n\n\nInterpretation of Results: To analyze this, a Pearson’s Chi-squared test was conducted on the contingency table. The output indicates a significant relationship between these variables, with a very low p-value (p &lt; 2.2e-16). This suggests that the observed frequencies of injury severity across different weather conditions and daylight statuses are unlikely to have occurred by chance alone, indicating a strong association between these factors."
  },
  {
    "objectID": "fp.html#visualization3-top-10-cars-which-involve-in-car-cashes",
    "href": "fp.html#visualization3-top-10-cars-which-involve-in-car-cashes",
    "title": "Final Project",
    "section": "visualization3 : Top 10 cars which involve in car cashes?",
    "text": "visualization3 : Top 10 cars which involve in car cashes?\n\n\nvehicle_counts &lt;- data %&gt;%\n  group_by(Vehicle.Make) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count)) # Sort by count in descending order\n\n# Take the top N most common vehicle makes for better visualization\ntop_n &lt;- 10 # You can adjust this value as needed\n\ntop_vehicle_counts &lt;- vehicle_counts %&gt;%\n  top_n(top_n, count)\n\nplot2 = ggplot(top_vehicle_counts, aes(x = reorder(Vehicle.Make, count), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"blue\") +  # Stacked bar plot with blue color\n  labs(title = \"Top 10 Most Common Vehicle Makes in Accidents\",\n       x = \"Vehicle Make\",\n       y = \"Number of Accidents\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.text = element_text(size = 14)) +  # Adjust text size\n  coord_flip() +  # Flip x and y axis\n  ylim(0, max(top_vehicle_counts$count) * 1.1)\n# plot2\n\n\nColumns Used :\n\ncount: This variable represents the number of accidents associated with each vehicle make. It is the variable of interest that we are analyzing and visualizing in the plot.\nVehicle.Make: This variable represents the make or manufacturer of the vehicles involved in accidents. It serves as the predictor variable in this analysis, as it is used to group the data and determine the count of accidents for each vehicle make.\n\n\nExplanation of the Code: This generates a bar plot showing the top 10 most common vehicle makes involved in accidents, with vehicle make names on the y-axis and the number of accidents on the x-axis. It uses dplyr to summarize and arrange the data, then ggplot2 for visualization."
  },
  {
    "objectID": "fp.html#hypo2.-are-certain-types-of-vehicles-more-likely-to-be-involved-in-collisions-at-night-compared-to-during-the-day",
    "href": "fp.html#hypo2.-are-certain-types-of-vehicles-more-likely-to-be-involved-in-collisions-at-night-compared-to-during-the-day",
    "title": "Final Project",
    "section": "hypo#2. Are certain types of vehicles more likely to be involved in collisions at night compared to during the day?",
    "text": "hypo#2. Are certain types of vehicles more likely to be involved in collisions at night compared to during the day?\nThe code aims to determine whether certain types of vehicles are more likely to be involved in collisions at night compared to during the day. Here’s a clear interpretation of the analysis:\n\nDaylight Collisions: This subset represents collisions that occurred during daylight hours.\nNighttime Collisions with Lights On: This subset represents collisions that occurred at night with lights on.\n\nChi-Square Test: A chi-square test of independence is performed to assess whether there is a significant association between vehicle types and the time of the collision (day or night).\n\n# Subset data for collisions during the day and at night\n#collisions_day &lt;- subset(data, Light == \"DAYLIGHT\")\n#collisions_night &lt;- subset(data, Light == \"DARK LIGHTS ON\")\n\n# Get the counts of each vehicle type for day and night collisions\n#counts_day &lt;- table(collisions_day$Vehicle.Body.Type)\n#counts_night &lt;- table(collisions_night$Vehicle.Body.Type)\n\n# Perform chi-square test of independence\n#chi_square_test &lt;- chisq.test(counts_day, counts_night)\n\n# Print the test results\n# print(chi_square_test)\n\n#**Interpretation of Results**: To analyze this, a Pearson's Chi-squared test was conducted comparing the counts of collisions involving different types of vehicles during the day and at night. The output indicates that there is no significant difference in the distribution of collisions across different types of vehicles between day and night, with a p-value of 0.2408. This suggests that the likelihood of different types of vehicles being involved in collisions is similar during both day and night."
  },
  {
    "objectID": "fp.html#hypo3.-do-drivers-distracted-by-electronic-devices-have-a-higher-rate-of-collisions-compared-to-drivers-distracted-by-other-factors",
    "href": "fp.html#hypo3.-do-drivers-distracted-by-electronic-devices-have-a-higher-rate-of-collisions-compared-to-drivers-distracted-by-other-factors",
    "title": "Final Project",
    "section": "hypo#3. Do drivers distracted by electronic devices have a higher rate of collisions compared to drivers distracted by other factors?",
    "text": "hypo#3. Do drivers distracted by electronic devices have a higher rate of collisions compared to drivers distracted by other factors?\nThe analysis aims to determine whether drivers distracted by electronic devices have a higher rate of collisions compared to drivers distracted by other factors. Here’s a clear interpretation of the results:\n\nDriver.Distracted.By: This variable indicates the factor(s) distracting the driver at the time of the collision. In this analysis, it’s used to differentiate between collisions involving electronic device distractions and those involving other distractions.\nCollision Counts by Distraction Type:\n\n\ncounts_electronic: This represents the count of collisions where the driver was distracted by electronic devices.\ncounts_other: This represents the count of collisions where the driver was distracted by factors other than electronic devices.\n\nChi-Square Test: A chi-square test of independence is performed to assess whether there is a significant difference in collision rates between the two groups of drivers.\n\n# Subset the data for drivers distracted by electronic devices\n#electronic_distracted &lt;- subset(data, Driver.Distracted.By == \"ELECTRONIC DEVICE\")\n\n# Subset the data for drivers distracted by other factors\n#other_distracted &lt;- subset(data, Driver.Distracted.By != \"ELECTRONIC DEVICE\" & Driver.Distracted.By != \"NOT DISTRACTED\")\n\n# Count the number of collisions for each distraction type\n#counts_electronic &lt;- nrow(electronic_distracted)\n#counts_other &lt;- nrow(other_distracted)\n\n# Perform chi-square test\n# chi_square_test &lt;- chisq.test(c(counts_electronic, counts_other))\n\n# Print the test results\n# print(chi_square_test)\n\n#**Interpretation of Results**: The question aims to determine if drivers distracted by electronic devices have a higher collision rate compared to those distracted by other factors. To analyze this, a Chi-squared test was conducted comparing the collision counts between drivers distracted by electronic devices and those distracted by other factors. The output indicates a significant difference between the two groups, with a very low p-value (p \\&lt; 2.2e-16). This suggests that drivers distracted by electronic devices indeed have a significantly higher collision rate compared to those distracted by other factors.\n\n\n## visualization2 : How does the distribution of car accidents vary geographically?\n\n# library(leaflet)\n#data &lt;- read.csv('/Users/manoharshasappa/Desktop/Stat_Final_project de/CrashReportingDriversData.csv')\n#data &lt;- na.omit(data) \n#map &lt;- leaflet(data) %&gt;%\n  #addTiles() %&gt;%\n  #addCircleMarkers(\n    #lng = ~Longitude,\n    #lat = ~Latitude,\n    #popup = ~as.character(Report.Number),\n    #label = ~as.character(Report.Number))\n\n# Print the map\n# map\n\n# -   Latitude and Longitude: These variables represent the geographical coordinates of the crash locations. They serve as predictor variables as they are used to specify the locations where circle markers will be placed on the map.\n\n# **Explanation of the Code:** This utilizes the Leaflet package in R to generate an interactive map. It begins by loading Leaflet and then initializes a map object. Using latitude and longitude data from a dataframe named 'data', it places circle markers on the map to represent specific locations, like crash sites. Each marker includes a popup and label showing the associated report number. Finally, it prints the interactive map, allowing users to explore the locations and corresponding report numbers within the R environment."
  },
  {
    "objectID": "Home.html",
    "href": "Home.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to Our Final Project Homepage!\n\n**We’re thrilled to welcome you to our project homepage dedicated to unraveling insights from traffic collisions in Montgomery County, MD. Together, we, a team of dedicated students from George Mason University, are embarking on this journey to analyze and explore data spanning from 2020 to 2024 sourced from the Automated Crash Reporting System (ACRS) of the Maryland State Police. Under the guidance of our professor, Dr. Isuru Dassanayake, Ph.D. in Statistics**\n\n\nAllow us to introduce our team members:\n\nMano Harsha Sappa (G01459796)\nVarun (G01475545)\nChandra Shekar (G01459798)\n\n\n\nBy exploring our project website, you’ll learn:\n\nExplore our project website to delve into the intricacies of traffic collisions in Montgomery County, MD. Through data analysis, uncover the multifaceted factors contributing to accidents, ranging from location and vehicle types to driver conditions and substance abuse involvement. Discover trends and patterns over time, enabling a deeper understanding of the dynamics at play and facilitating informed decision-making. Engage with interactive visualizations that breathe life into the data, simplifying complex information and highlighting key insights. Delve into the community impact of our findings, learning how they can shape road safety initiatives in Montgomery County and beyond, and how you can contribute to creating safer roads for everyone."
  },
  {
    "objectID": "Conclusion.html",
    "href": "Conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "In conclusion, the Research Design encompasses a comprehensive methodology to investigate various aspects of road safety and collision outcomes. Through a series of questions, data visualizations, hypothesis testing, and predictive modeling, the research aims to provide valuable insights into crash patterns, injury severity determinants, and predictive capabilities. The data visualizations, including crash frequency per year, geographical distribution of fatalities, and the most common vehicle makes involved in accidents, offer a clear understanding of the trends and patterns in collision occurrences. Hypothesis testing delves into the relationships between factors such as weather conditions, vehicle types, and collision rates, providing empirical evidence to support or refute the proposed hypotheses. Additionally, predictive modeling endeavors to forecast injury severity and vehicle damage extent based on various contributing factors, offering practical applications for enhancing road safety measures. Overall, the Research Design serves as a foundational framework for the subsequent analysis and interpretation of data, ultimately aiming to contribute to the development of effective strategies for accident prevention and mitigation."
  },
  {
    "objectID": "Conclusion.html#future-questions",
    "href": "Conclusion.html#future-questions",
    "title": "Conclusion",
    "section": "Future Questions:",
    "text": "Future Questions:\n\nFuture questions: 1. How do collisions contribute to environmental pollution and habitat destruction, and how can this information be used to guide urban planning and development decisions? 2. How can data from in-vehicle telematics systems be integrated with collision data to provide more accurate risk assessments?"
  },
  {
    "objectID": "Conclusion.html#references",
    "href": "Conclusion.html#references",
    "title": "Conclusion",
    "section": "References:",
    "text": "References:\n\nMontgomery County of Maryland - Crash reporting - Drivers data. (2024, February 9). url: https://catalog.data.gov/dataset/crash-reporting-drivers-data."
  }
]