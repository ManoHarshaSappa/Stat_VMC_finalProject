labs(title = "Crash Frequency per Year",
x = "Year",
y = "Number of Crashes") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
plot1
# Print the test results
print(chi_square_test)
# Contingency table of Weather, Light, and Injury Severity
contingency_table <- table(data$Weather, data$Light, data$Injury.Severity)
# Remove any empty dimensions
contingency_table <- margin.table(contingency_table, c(1, 2))
# Chi-square test of independence
chi_square_test <- chisq.test(contingency_table)
# Print the test results
print(chi_square_test)
vehicle_counts <- data %>%
group_by(Vehicle.Make) %>%
summarise(count = n()) %>%
arrange(desc(count)) # Sort by count in descending order
# Take the top N most common vehicle makes for better visualization
top_n <- 10 # You can adjust this value as needed
top_vehicle_counts <- vehicle_counts %>%
top_n(top_n, count)
plot2 = ggplot(top_vehicle_counts, aes(x = reorder(Vehicle.Make, count), y = count)) +
geom_bar(stat = "identity", fill = "blue") +  # Stacked bar plot with blue color
labs(title = "Top 10 Most Common Vehicle Makes in Accidents",
x = "Vehicle Make",
y = "Number of Accidents") +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text = element_text(size = 14)) +  # Adjust text size
coord_flip() +  # Flip x and y axis
ylim(0, max(top_vehicle_counts$count) * 1.1)
# plot2
plot2
# Subset data for collisions during the day and at night
collisions_day <- subset(data, Light == "DAYLIGHT")
collisions_night <- subset(data, Light == "DARK LIGHTS ON")
# Get the counts of each vehicle type for day and night collisions
counts_day <- table(collisions_day$Vehicle.Body.Type)
counts_night <- table(collisions_night$Vehicle.Body.Type)
# Perform chi-square test of independence
chi_square_test <- chisq.test(counts_day, counts_night)
# Print the test results
print(chi_square_test)
# Subset the data for drivers distracted by electronic devices
electronic_distracted <- subset(data, Driver.Distracted.By == "ELECTRONIC DEVICE")
# Subset the data for drivers distracted by other factors
other_distracted <- subset(data, Driver.Distracted.By != "ELECTRONIC DEVICE" & Driver.Distracted.By != "NOT DISTRACTED")
# Count the number of collisions for each distraction type
counts_electronic <- nrow(electronic_distracted)
counts_other <- nrow(other_distracted)
# Perform chi-square test
chi_square_test <- chisq.test(c(counts_electronic, counts_other))
# Print the test results
print(chi_square_test)
# Subset the dataset to include only the required columns
traffic_data <- data[, c("Traffic.Control", "Injury.Severity")]
# Remove rows with any missing values
traffic_data <- na.omit(traffic_data)
library(ggplot2)
library(dplyr)
traffic_data[traffic_data == "N/A"] <- NA
# Remove rows with any missing values
traffic_data <- na.omit(traffic_data)
# Check if there are any missing values left
print(sum(is.na(traffic_data)))
collision_counts <- traffic_data %>%
group_by(Traffic.Control) %>%
summarise(Collision_Count = n())
# Calculate collision rates for each traffic control type
total_collisions <- nrow(traffic_data)
collision_rates <- collision_counts %>%
mutate(Collision_Rate = Collision_Count / total_collisions)
# Statistical Analysis
# Perform chi-square test to compare collision rates between different traffic controls
chi_square_test <- chisq.test(traffic_data$Traffic.Control, traffic_data$Injury.Severity)
# Visualization
par(mfrow=c(1, 2))  # Set up a 1x2 plotting grid
# Create a bar plot using ggplot2
plot3 = ggplot(collision_counts, aes(x = reorder(Traffic.Control, -Collision_Count), y = Collision_Count)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Collision Counts by Traffic Control Type",
x = "Traffic Control Type",
y = "Collision Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#plot3
plot3
# Visualization
par(mfrow=c(1, 2))  # Set up a 1x2 plotting grid
# Statistical Analysis
# Perform chi-square test to compare collision rates between different traffic controls
chi_square_test <- chisq.test(traffic_data$Traffic.Control, traffic_data$Injury.Severity)
collision_rates <- collision_counts %>%
mutate(Collision_Rate = Collision_Count / total_collisions)
# Remove rows with any missing values
traffic_data <- na.omit(traffic_data)
# Check if there are any missing values left
print(sum(is.na(traffic_data)))
collision_counts <- traffic_data %>%
group_by(Traffic.Control) %>%
summarise(Collision_Count = n())
# Calculate collision rates for each traffic control type
total_collisions <- nrow(traffic_data)
collision_rates <- collision_counts %>%
mutate(Collision_Rate = Collision_Count / total_collisions)
# Statistical Analysis
# Perform chi-square test to compare collision rates between different traffic controls
chi_square_test <- chisq.test(traffic_data$Traffic.Control, traffic_data$Injury.Severity)
# Visualization
par(mfrow=c(1, 2))  # Set up a 1x2 plotting grid
# Create a bar plot using ggplot2
plot3 = ggplot(collision_counts, aes(x = reorder(Traffic.Control, -Collision_Count), y = Collision_Count)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Collision Counts by Traffic Control Type",
x = "Traffic Control Type",
y = "Collision Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(chi_square_test)
library(ggplot2)
library(dplyr)
# Assuming your dataset is called 'location_data' and contains columns 'Latitude' and 'Longitude'
# Select latitude and longitude columns
location_data <- data %>% select(Latitude, Longitude)
# Normalize data
normalized_data <- scale(location_data)
# Initialize vector to store within-cluster sum of squares (WCSS)
wcss <- vector()
# Iterate over different values of k
for (i in 1:10) {
# Apply K-Means algorithm
kmeans_model <- kmeans(normalized_data, centers = i)
# Store within-cluster sum of squares (WCSS)
wcss[i] <- kmeans_model$tot.withinss
}
# Plot the elbow curve
plot4 <- ggplot(data = data.frame(k = 1:10, WCSS = wcss), aes(x = k, y = WCSS)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Elbow Method for Optimal K",
x = "Number of Clusters (k)",
y = "Within-Cluster Sum of Squares (WCSS)") +
scale_x_continuous(breaks = 1:10)
plot4
# Load required libraries
library(ggplot2)
library(dplyr)
# Assuming your dataset is called 'location_data' and contains columns 'Latitude' and 'Longitude'
# Select latitude and longitude columns
location_data <- data %>% select(Latitude, Longitude)
# Normalize data
normalized_data <- scale(location_data)
# Initialize vector to store within-cluster sum of squares (WCSS)
wcss <- vector()
# Iterate over different values of k
for (i in 1:10) {
# Apply K-Means algorithm
kmeans_model <- kmeans(normalized_data, centers = i)
Store within-cluster sum of squares (WCSS)
# Load required libraries
library(ggplot2)
library(dplyr)
# Assuming your dataset is called 'location_data' and contains columns 'Latitude' and 'Longitude'
# Select latitude and longitude columns
location_data <- data %>% select(Latitude, Longitude)
# Normalize data
normalized_data <- scale(location_data)
# Initialize vector to store within-cluster sum of squares (WCSS)
wcss <- vector()
# Iterate over different values of k
for (i in 1:10) {
# Apply K-Means algorithm
kmeans_model <- kmeans(normalized_data, centers = i)
#Store within-cluster sum of squares (WCSS)
wcss[i] <- kmeans_model$tot.withinss}
# Plot the elbow curve
plot4 = elbow_plot <- ggplot(data = data.frame(k = 1:10, WCSS = wcss), aes(x = k, y = WCSS)) +
geom_line(color = "blue") +
geom_point(color = "red") +
labs(title = "Elbow Method for Optimal K",
x = "Number of Clusters (k)",
y = "Within-Cluster Sum of Squares (WCSS)") +
scale_x_continuous(breaks = 1:10)
plot4
# Print the test results
print(chi_square_test)
print(chi_square_test)
# Print the test results
print(chi_square_test)
# Print the test results
print(chi_square_test)
# Load required library
library(randomForest)
library(caret)
library(caret)
# Select relevant columns for modeling
selected_cols <- c("Weather", "Surface.Condition", "Collision.Type", "Injury.Severity")
# Subset the data
subset_data <- data[selected_cols]
# Remove rows with any missing values
subset_data_clean <- subset_data[complete.cases(subset_data), ]
subset_data_clean
# Convert 'N/A' strings to NA
subset_data_clean[subset_data_clean == "N/A"] <- NA
# Remove rows with any missing values
subset_data_clean <- na.omit(subset_data_clean)
# Check if there are any missing values left
print(sum(is.na(subset_data_clean)))
subset_data_clean
# Replace blank values with NA
subset_data_clean[subset_data_clean == ""] <- NA
# Remove rows with any missing values
subset_data_clean <- na.omit(subset_data_clean)
# Check if there are any missing values left
print(sum(is.na(subset_data_clean)))
subset_data_clean
# Convert all columns to factors
subset_data_clean <- as.data.frame(lapply(subset_data_clean, as.factor))
# Verify the conversion
str(subset_data_clean)
# Load required library
library(randomForest)
library(caret)
str(subset_data_clean)
# Set seed for reproducibility
set.seed(123)
# Split the data into training and testing sets
train_indices <- createDataPartition(subset_data_clean$Injury.Severity, p = 0.8, list = FALSE)
train_data <- subset_data_clean[train_indices, ]
test_data <- subset_data_clean[-train_indices, ]
train_data
# Fit random forest model
model <- randomForest(Injury.Severity ~ ., data = train_data, ntree = 500)
# Print model summary
print(model)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Create confusion matrix
conf_matrix <- table(predictions, test_data$Injury.Severity)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Create confusion matrix
conf_matrix <- table(predictions, test_data$Injury.Severity)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Evaluate the model using confusion matrix
conf_matrix <- table(test_data$Injury.Severity, predictions)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print accuracy
print(paste("Accuracy:", accuracy))
importance(model)
varImpPlot(model)
# Predict on the test set
predictions <- predict(model, newdata = test_data)
# Confusion matrix
conf_mat <- table(Actual = test_data$Injury.Severity, Predicted = predictions)
print("Confusion Matrix:")
print(conf_mat)
# Accuracy
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)
print(paste("Accuracy:", accuracy))
# Precision
precision <- diag(conf_mat) / colSums(conf_mat)
print(paste("Precision:", precision))
# Recall (Sensitivity)
recall <- diag(conf_mat) / rowSums(conf_mat)
print(paste("Recall:", recall))
# F1-score
f1_score <- 2 * (precision * recall) / (precision + recall)
print(paste("F1-score:", f1_score))
library(dplyr)
# Assuming your dataset is named 'crash_data'
# Select relevant columns for modeling
selected_cols <- c("Weather", "Surface.Condition", "Collision.Type", "Injury.Severity")
# Subset the data
crash_data1 <- data[selected_cols]
# Remove rows with any missing values
crash_data1 <- crash_data1[complete.cases(crash_data1), ]
crash_data1
# Convert 'N/A' strings to NA
crash_data1[crash_data1 == "N/A"] <- NA
# Remove rows with any missing values
crash_data1 <- na.omit(crash_data1)
# Check if there are any missing values left
print(sum(is.na(crash_data1)))
crash_data1
# Convert 'N/A' strings to NA
crash_data1[crash_data1 == ""] <- NA
# Remove rows with any missing values
crash_data1 <- na.omit(crash_data1)
# Check if there are any missing values left
print(sum(is.na(crash_data1)))
crash_data1
crash_data1$Severe_Injury <- ifelse(crash_data1$Injury.Severity %in% c("SUSPECTED MINOR INJURY", "SUSPECTED SERIOUS INJURY", "FATAL INJURY"), 1, 0)
crash_data1 <- crash_data1[, -which(names(crash_data1) == "Injury.Severity")]
crash_data1
logistic_model <- glm(Severe_Injury ~ ., data = crash_data1, family = binomial)
summary(logistic_model)
# Extract coefficients and standard errors
coefficients <- summary(logistic_model)$coefficients[, "Estimate"]
standard_errors <- summary(logistic_model)$coefficients[, "Std. Error"]
# Predict probabilities using the logistic regression model
predicted_probs <- predict(logistic_model, type = "response")
# Convert probabilities to predicted classes
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
# Actual classes
actual_classes <- crash_data1$Severe_Injury
# Accuracy
accuracy <- mean(predicted_classes == actual_classes)
cat("Accuracy:", accuracy, "\n")
# AUC-ROC
library(pROC)
roc_obj <- roc(actual_classes, predicted_probs)
auc_roc <- auc(roc_obj)
cat("AUC-ROC:", auc_roc, "\n")
# Install and load the pROC package if you haven't already
install.packages("pROC")
library(pROC)
# Assuming 'predicted_probs' contains the predicted probabilities and 'actual_classes' contains the actual classes (0 or 1)
roc_obj <- roc(actual_classes, predicted_probs)
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Add text with AUC value
text(0.8, 0.2, paste("AUC =", round(auc(roc_obj), 4)), col = "blue")
install.packages("pROC")
# Install and load the pROC package if you haven't already
install.packages("pROC")
library(pROC)
# Assuming 'predicted_probs' contains the predicted probabilities and 'actual_classes' contains the actual classes (0 or 1)
roc_obj <- roc(actual_classes, predicted_probs)
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Add text with AUC value
text(0.8, 0.2, paste("AUC =", round(auc(roc_obj), 4)), col = "blue")
install.packages("pROC")
install.packages("pROC")
# Install and load the pROC package if you haven't already
library(pROC)
install.packages("pROC")
install.packages("pROC")
# Install and load the pROC package if you haven't already
install.packages("pROC")
library(pROC)
# Assuming 'predicted_probs' contains the predicted probabilities and 'actual_classes' contains the actual classes (0 or 1)
roc_obj <- roc(actual_classes, predicted_probs)
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Add text with AUC value
text(0.8, 0.2, paste("AUC =", round(auc(roc_obj), 4)), col = "blue")
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Add text with AUC value
text(0.8, 0.2, paste("AUC =", round(auc(roc_obj), 4)), col = "blue")
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Convert 'N/A' strings to NA
subset_data_clean[subset_data_clean == "N/A"] <- NA
# Remove rows with any missing values
subset_data_clean <- na.omit(subset_data_clean)
# Check if there are any missing values left
print(sum(is.na(subset_data_clean)))
subset_data_clean
head(data)
head(subset_data_clean)
head(subset_data_clean)
subset_data_clean
subset_data_clean
crash_data1
subset_data
subset_data
subset_data
# Print model summary
print(model)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print accuracy
print(paste("Accuracy:", accuracy))
importance(model)
i
varImpPlot(model)
varImpPlot(model)
varImpPlot(model)
importance(model)
# Convert all columns to factors
subset_data_clean <- as.data.frame(lapply(subset_data_clean, as.factor))
# Verify the conversion
# str(subset_data_clean)
# Load required library
library(randomForest)
library(caret)
str(subset_data_clean)
# Set seed for reproducibility
set.seed(123)
# Split the data into training and testing sets
train_indices <- createDataPartition(subset_data_clean$Injury.Severity, p = 0.8, list = FALSE)
train_data <- subset_data_clean[train_indices, ]
test_data <- subset_data_clean[-train_indices, ]
train_data
# Fit random forest model
model <- randomForest(Injury.Severity ~ ., data = train_data, ntree = 500)
# Print model summary
# print(model)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Create confusion matrix
conf_matrix <- table(predictions, test_data$Injury.Severity)
# Calculate accuracy
# accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Evaluate the model using confusion matrix
conf_matrix <- table(test_data$Injury.Severity, predictions)
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Print accuracy
# print(paste("Accuracy:", accuracy))
importance(model)
varImpPlot(model)
# Predict on the test set
predictions <- predict(model, newdata = test_data)
# Confusion matrix
conf_mat <- table(Actual = test_data$Injury.Severity, Predicted = predictions)
print("Confusion Matrix:")
print(conf_mat)
# Accuracy
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)
print(paste("Accuracy:", accuracy))
# Precision
precision <- diag(conf_mat) / colSums(conf_mat)
print(paste("Precision:", precision))
# Recall (Sensitivity)
recall <- diag(conf_mat) / rowSums(conf_mat)
print(paste("Recall:", recall))
# F1-score
f1_score <- 2 * (precision * recall) / (precision + recall)
print(paste("F1-score:", f1_score))
library(dplyr)
# Assuming your dataset is named 'crash_data'
# Select relevant columns for modeling
selected_cols <- c("Weather", "Surface.Condition", "Collision.Type", "Injury.Severity")
# Subset the data
crash_data1 <- data[selected_cols]
# Remove rows with any missing values
crash_data1 <- crash_data1[complete.cases(crash_data1), ]
crash_data1
# Convert 'N/A' strings to NA
crash_data1[crash_data1 == "N/A"] <- NA
# Remove rows with any missing values
crash_data1 <- na.omit(crash_data1)
# Check if there are any missing values left
print(sum(is.na(crash_data1)))
crash_data1
# Convert 'N/A' strings to NA
crash_data1[crash_data1 == ""] <- NA
# Remove rows with any missing values
crash_data1 <- na.omit(crash_data1)
# Check if there are any missing values left
print(sum(is.na(crash_data1)))
crash_data1
crash_data1$Severe_Injury <- ifelse(crash_data1$Injury.Severity %in% c("SUSPECTED MINOR INJURY", "SUSPECTED SERIOUS INJURY", "FATAL INJURY"), 1, 0)
crash_data1 <- crash_data1[, -which(names(crash_data1) == "Injury.Severity")]
crash_data1
logistic_model <- glm(Severe_Injury ~ ., data = crash_data1, family = binomial)
summary(logistic_model)
# Extract coefficients and standard errors
coefficients <- summary(logistic_model)$coefficients[, "Estimate"]
standard_errors <- summary(logistic_model)$coefficients[, "Std. Error"]
# Predict probabilities using the logistic regression model
predicted_probs <- predict(logistic_model, type = "response")
# Convert probabilities to predicted classes
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
# Actual classes
actual_classes <- crash_data1$Severe_Injury
# Accuracy
accuracy <- mean(predicted_classes == actual_classes)
cat("Accuracy:", accuracy, "\n")
# AUC-ROC
library(pROC)
roc_obj <- roc(actual_classes, predicted_probs)
auc_roc <- auc(roc_obj)
cat("AUC-ROC:", auc_roc, "\n")
# Install and load the pROC package if you haven't already
library(pROC)
# Assuming 'predicted_probs' contains the predicted probabilities and 'actual_classes' contains the actual classes (0 or 1)
roc_obj <- roc(actual_classes, predicted_probs)
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Add text with AUC value
# text(0.8, 0.2, paste("AUC =", round(auc(roc_obj), 4)), col = "blue")#
# Extract coefficients and standard errors
coefficients <- summary(logistic_model)$coefficients[, "Estimate"]
standard_errors <- summary(logistic_model)$coefficients[, "Std. Error"]
# Predict probabilities using the logistic regression model
predicted_probs <- predict(logistic_model, type = "response")
# Convert probabilities to predicted classes
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
# Actual classes
actual_classes <- crash_data1$Severe_Injury
# Accuracy
accuracy <- mean(predicted_classes == actual_classes)
cat("Accuracy:", accuracy, "\n")
# AUC-ROC
library(pROC)
roc_obj <- roc(actual_classes, predicted_probs)
auc_roc <- auc(roc_obj)
cat("AUC-ROC:", auc_roc, "\n")
# Plot ROC curve
plot(roc_obj, main = "ROC Curve", col = "blue")
# Add text with AUC value
text(0.8, 0.2, paste("AUC =", round(auc(roc_obj), 4)), col = "blue")#
